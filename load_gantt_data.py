from datetime import datetime, timedelta
import pandas as pd
import streamlit as st
from google_config import get_gspread_client, get_target_book_info
from typing import Tuple

# === ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæƒ…å ± === #
MASTER_SHEET_NAME = "ãƒã‚¹ã‚¿"
SHIFT_MIRROR_SHEET_NAME = "å‹¤å‹™ã‚·ãƒ•ãƒˆmirror"

@st.cache_data(ttl=60)
def load_fixed_end_times(spreadsheet_id: str) -> dict:
    """
    å‹¤å‹™ã‚·ãƒ•ãƒˆmirrorã‚·ãƒ¼ãƒˆã‹ã‚‰ä½œæ¥­è€…ã”ã¨ã®å›ºå®šçµ‚æ¥­æ™‚é–“ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰ã€‚
    """
    try:
        client = get_gspread_client()
        sheet = client.open_by_key(spreadsheet_id).worksheet(SHIFT_MIRROR_SHEET_NAME)
        shift_data = sheet.get_all_records()
        return {
            row.get("æ°å"): row.get("çµ‚æ¥­æ™‚é–“")
            for row in shift_data
            if row.get("æ°å") and row.get("çµ‚æ¥­æ™‚é–“")
        }
    except Exception as e:
        return {}

def get_rows_for_date(sheet, target_date_str):
    # ğŸ”¹ Aåˆ—ï¼ˆæ—¥ä»˜åˆ—ï¼‰ã ã‘ã‚’å–å¾—ï¼ˆAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆâ‘ ï¼‰
    date_column = sheet.col_values(1)
    if not date_column or len(date_column) < 2:
        return [], []

    headers = ["æ—¥ä»˜", "ãƒ–ãƒƒã‚¯", "ä½œæ¥­è€…", "ã‚¨ãƒªã‚¢", "ç³»çµ±", "å“ç¨®", "é–‹å§‹æ™‚é–“", "ä½œæ¥­å†…å®¹", "æŒ‡ç¤º"]

    # ğŸ”¹ ä¸€è‡´ã™ã‚‹è¡Œç•ªå·ï¼ˆ1ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’æŠ½å‡ºï¼ˆâ€»ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ = è¡Œ1 ã‚’é™¤å¤–ï¼‰
    matching_indices = [i + 1 for i, val in enumerate(date_column[1:], start=1) if val == target_date_str]
    if not matching_indices:
        return [], headers

    # ğŸ”¹ ä¸€æ‹¬å–å¾—ã®ç¯„å›²ã‚’æ±ºå®š
    start_row = min(matching_indices)
    end_row = max(matching_indices)
    cell_range = f"A{start_row}:I{end_row}"

    # ğŸ”¹ ä¸€æ‹¬å–å¾—ï¼ˆAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆâ‘¡ï¼‰
    cell_data = sheet.get(cell_range)

    # ğŸ”¹ è¡Œâ†’è¾æ›¸å¤‰æ›ï¼ˆåˆ—æ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯è£œå®Œï¼‰
    records = []
    for rel_i, abs_row in enumerate(range(start_row, end_row + 1)):
        if abs_row in matching_indices and rel_i < len(cell_data):
            row = cell_data[rel_i]
            padded_row = row + [""] * (len(headers) - len(row))
            record = dict(zip(headers, padded_row))
            records.append(record)

    return records, headers

def process_all_data(rows, target_str, fixed_end_times):
    tasks_by_worker = {}
    for row in rows:
        name = row.get("ä½œæ¥­è€…", "").strip()
        if not name:
            continue
        tasks_by_worker.setdefault(name, []).append(row)

    for task_list in tasks_by_worker.values():
        task_list.sort(key=lambda r: datetime.strptime(
            f"{target_str} {r.get('é–‹å§‹æ™‚é–“')}", "%Y/%m/%d %H:%M") if r.get("é–‹å§‹æ™‚é–“") else datetime.max)

    records = []
    warnings = []

    for name, task_list in tasks_by_worker.items():
        for i, row in enumerate(task_list):
            start = row.get("é–‹å§‹æ™‚é–“")
            end = row.get("çµ‚äº†æ™‚é–“")

            if not start:
                continue

            try:
                start_dt = datetime.strptime(f"{target_str} {start}", "%Y/%m/%d %H:%M")
            except Exception as e:
                warnings.append(f"é–‹å§‹æ™‚é–“ã®å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e} â†’ {start}")
                continue

            if end:
                try:
                    end_dt = datetime.strptime(f"{target_str} {end}", "%Y/%m/%d %H:%M")
                except Exception as e:
                    warnings.append(f"çµ‚äº†æ™‚é–“ã®å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e} â†’ {end}")
                    continue
            elif i + 1 < len(task_list):
                next_start = task_list[i + 1].get("é–‹å§‹æ™‚é–“")
                try:
                    end_dt = datetime.strptime(f"{target_str} {next_start}", "%Y/%m/%d %H:%M")
                except:
                    end_dt = start_dt + timedelta(hours=1)
            else:
                fixed_end = fixed_end_times.get(name, "17:00")
                try:
                    end_dt = datetime.strptime(f"{target_str} {fixed_end}", "%Y/%m/%d %H:%M")
                except:
                    end_dt = start_dt + timedelta(hours=1)

            if start_dt >= end_dt:
                warnings.append(f"âš  ä½œæ¥­è€…ã€Œ{name}ã€ã®é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ãŒä¸€è‡´ã¾ãŸã¯é€†è»¢ã—ã¦ã„ã¾ã™ â†’ {start} - {end_dt.strftime('%H:%M')}")
                continue

            area = row.get("ã‚¨ãƒªã‚¢", "")
            line = row.get("ç³»çµ±", "")
            variety = row.get("å“ç¨®", "")
            task = row.get("ä½œæ¥­å†…å®¹", "")
            instruction = row.get("æŒ‡ç¤º", "")

            line1 = f"{area} - {line} {variety}".strip()
            line2 = f"{start} {task} {instruction}".strip()
            task_label = f"{line1}<br>{line2}"

            records.append({
                "ä½œæ¥­è€…": name,
                "ä½œæ¥­é–‹å§‹": start_dt,
                "ä½œæ¥­çµ‚äº†": end_dt,
                "ä½œæ¥­å†…å®¹": task_label,
                "ã‚¨ãƒªã‚¢": area,
                "ãƒ–ãƒƒã‚¯": row.get("ãƒ–ãƒƒã‚¯", "")
            })

    return pd.DataFrame(records), warnings

def load_gantt_data_for_date(target_date: datetime.date, book_type="å…¨ä½“", area_filter="å…¨ä½“") -> Tuple[pd.DataFrame, list[str], pd.DataFrame]:
    client = get_gspread_client()
    book_info = get_target_book_info("ä½œæ¥­æŒ‡ç¤º", target_date)
    sheet = client.open_by_key(book_info["spreadsheet_id"]).worksheet(book_info["sheet_name"])

    target_str = target_date.strftime("%Y/%m/%d")
    rows, _ = get_rows_for_date(sheet, target_str)

    if not rows:
        return pd.DataFrame(), [], pd.DataFrame()

    fixed_end_times = load_fixed_end_times(book_info["spreadsheet_id"])
    full_df, warnings = process_all_data(rows, target_str, fixed_end_times)
    full_df_original = full_df.copy()

    if book_type != "å…¨ä½“":
        full_df = full_df[full_df["ãƒ–ãƒƒã‚¯"] == book_type]

    if area_filter != "å…¨ä½“":
        full_df = full_df[full_df["ã‚¨ãƒªã‚¢"] == area_filter]

    return full_df.copy(), warnings, full_df_original